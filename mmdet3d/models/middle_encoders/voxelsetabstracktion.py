# Copyright (c) OpenMMLab. All rights reserved.
import time

import torch
import torch.nn as nn
import torch.nn.functional as F
from mmcv.cnn.bricks import build_norm_layer
from mmcv.ops import PointsSampler, gather_points
from mmengine.model import BaseModule

from mmdet3d.models.layers.pointnet_modules import build_sa_module
from mmdet3d.registry import MODELS
from typing import List,Dict,Tuple
from torch import Tensor
import torch.nn as nn
from mmdet3d.structures.det3d_data_sample import InstanceData
@MODELS.register_module()
class VoxelSetAbstraction(BaseModule):
    r"""Voxel set abstraction module for PVRCNN and PVRCNN++.

    Args:
        keypoints_sampler (dict or ConfigDict): Key point sampler config.
            It is used to build `PointsSampler` to sample key points from
            raw points.
        voxel_size (list[float], optional): Size of voxels.
            Defaults to [0.05, 0.05, 0.1].
        point_cloud_range (list[float], optional): Point cloud range.
            Defaults to [0, -40, -3, 70.4, 40, 1].
        rawpoint_sa_cfg (dict or ConfigDict, optional): SA module cfg. Used to gather
            key points features from raw points.
        voxel_sa_cfg_list (List[dict or ConfigDict], optional): List of SA module cfg.
            Used to gather key points features from multi-level voxel features.
        bev_cfg (dict or ConfigDict, optional): Bev features encode cfg. Used to gather
            key points features from Bev features.
        voxel_center_as_source (bool, optional): Whether used voxel centers as key points
            to extract features. Default to False.
        fused_out_channels (int, optional): Key points feature output channel num after fused.
            Default to 128.
        norm_cfg (dict[str], optional): Config of normalization layer. Default used
            dict(type='BN1d', eps=1e-5, momentum=0.1)
    """
    def __init__(self,
                 keypoints_sampler: dict,
                 voxel_size: list = [0.05, 0.05, 0.1],
                 point_cloud_range: list = [0, -40, -3, 70.4, 40, 1],
                 rawpoint_sa_cfg: dict = None,
                 voxel_sa_cfg_list: List[dict] = None,
                 bev_cfg: dict = None,
                 voxel_center_as_source: bool = False,
                 fused_out_channels: int = 128,
                 norm_cfg: dict = dict(type='BN1d', eps=1e-5, momentum=0.1)) -> None:
        super().__init__()
        self.voxel_size = voxel_size
        self.point_cloud_range = point_cloud_range
        self.voxel_center_as_source = voxel_center_as_source

        self.voxel_sa_cfg_list = voxel_sa_cfg_list
        self.rawpoint_sa_cfg = rawpoint_sa_cfg
        self.bev_cfg = bev_cfg

        self.keypoints_sampler = PointsSampler(**keypoints_sampler)

        in_channels = 0
        if self.bev_cfg is not None:
            in_channels += self.bev_cfg.in_channels

        if self.rawpoint_sa_cfg is not None:
            self.rawpoints_sa_layer = build_sa_module(self.rawpoint_sa_cfg)
            in_channels += sum(
                [x[-1] for x in self.rawpoints_sa_layer.mlp_channels])

        if self.voxel_sa_cfg_list is not None:
            self.voxel_sa_layers = nn.ModuleList()
            self.downsample_scale_factor = []
            for idx, voxel_sa_cfg in enumerate(self.voxel_sa_cfg_list):
                self.downsample_scale_factor.append(
                    voxel_sa_cfg.pop('scale_factor'))
                cur_layer = build_sa_module(voxel_sa_cfg)
                self.voxel_sa_layers.append(cur_layer)
                in_channels += sum([x[-1] for x in cur_layer.mlp_channels])

        self.point_feature_fusion = nn.Sequential(
            nn.Linear(in_channels, fused_out_channels, bias=False),
            build_norm_layer(norm_cfg, fused_out_channels)[1], nn.ReLU())

    def interpolate_from_bev_features(self, keypoints: Tensor, bev_features: Tensor,
                                      scale_factor: int) -> Tensor:
        """Interpolate from Bev features by key points.

        Args:
            keypoints (torch.Tensor): Sampled key points from raw points,
                shape is (B,N,3)，where N is key points num.
            bev_features (torch.Tensor): Bev features, shape is (B,H,W,C).
            scale_factor (int): Down sample scale factor.

        Returns:
            torch.Tensor: Key points Bev features.
        """
        # TODO: Here is different from OpenPCDet in inference,
        # but I think it doesn't influence trained model accuracy.
        _, _, y_grid, x_grid = bev_features.shape

        voxel_size_xy = keypoints.new_tensor(self.voxel_size[:2])

        bev_tl_grid_cxy = keypoints.new_tensor(self.point_cloud_range[:2])
        bev_br_grid_cxy = keypoints.new_tensor(self.point_cloud_range[3:5])
        bev_tl_grid_cxy.add_(0.5 * voxel_size_xy * scale_factor)
        bev_br_grid_cxy.sub_(0.5 * voxel_size_xy * scale_factor)

        xy = keypoints[..., :2]

        grid_sample_xy = (xy - bev_tl_grid_cxy[None, None, :]) / (
            (bev_br_grid_cxy - bev_tl_grid_cxy)[None, None, :])

        grid_sample_xy = (grid_sample_xy * 2 - 1).unsqueeze(1)
        point_bev_features = F.grid_sample(bev_features,
                                           grid=grid_sample_xy,
                                           align_corners=True)
        return point_bev_features.squeeze(2).permute(0, 2, 1).contiguous()

    def aggregate_keypoint_features_from_one_source(self,
                                                    aggregate_module: nn.Module,
                                                    points_xyz: Tensor,
                                                    features: Tensor = None,
                                                    target_xyz: Tensor = None) -> Tuple:
        """Aggregate keypoint features from one source by aggregate module.

        Args:
            aggregate_module (nn.Module): A SA module is used to aggregate features.
            points_xyz (torch.Tensor): (B, N, 3) xyz coordinates of the features.
            features (torch.Tensor, optional): (B, C, N) features of each point.
                Default: None.
            target_xyz (torch.Tensor, optional): (B, M, 3) new coords of the outputs.
                Default: None.

        Returns:
            Tensor: (B, M, 3) where M is the number of points.
                New features xyz.
            Tensor: (B, M, sum_k(mlps[k][-1])) where M is the number
                of points. New feature descriptors.
            Tensor: (B, M) where M is the number of points.
                Index of the features.
        """
        new_xyz, pooled_features, indices = aggregate_module(
            points_xyz=points_xyz, features=features, target_xyz=target_xyz)
        return new_xyz, pooled_features.transpose(1, 2), indices

    def sample_key_points(self, batch_inputs_dict: dict) -> Tensor:
        """Sample key points from raw input points.

        Args:
            batch_inputs_dict (dict): The model input dict which include
                'points', 'voxel_dict' keys.

                    - points (list[torch.Tensor]): Point cloud of each sample.
                    - voxel_dict (dict , optional): Voxel dict of each sample.

        Returns:
            torch.Tensor: Batch key points, shape is (B,N,D),
                where N is key points num, D is raw points dim.
        """
        if self.voxel_center_as_source:
            coors = batch_inputs_dict['voxel_dict']['coors']
            batch_key_points,_ = self.get_voxel_centers(coors, scale_factor=1)
        else:
            raw_points = self.padded_batch_points(batch_inputs_dict['points'])
            points_xyz = raw_points[:, :, :3].contiguous()
            points_flipped = raw_points.transpose(1, 2).contiguous()
            indices = self.keypoints_sampler(points_xyz, None)
            batch_key_points = gather_points(points_flipped,
                                       indices).transpose(1, 2).contiguous()
        return batch_key_points

    def padded_batch_points(self, points_list: List[Tensor]) -> Tensor:
        """Padded points list to a Tensor.

        Args:
            points_list (List[torch.Tensor]): Point cloud of each sample.

        Returns:
            torch.Tensor: Batch points tensor, shape is (B,N,D), where N is points num,
            D is raw points dim.
        """
        padded_points_list = []
        max_points_num = max(points.shape[0] for points in points_list)
        for points in points_list:
            padded_points_list.append(
                F.pad(points, (0, 0, 0, max_points_num - points.shape[0])))
        batch_points = torch.stack(padded_points_list, dim=0)
        return batch_points

    def get_voxel_centers(self, coors: Tensor, scale_factor: int = 1) -> Tuple:
        """Get voxel centers.

        Args:
            coors (torch.Tensor): The coordinates of each voxel.
            scale_factor (int): Down sample scale factor.

        Returns:
            Tuple[torch.Tensor, list]: Return batch voxel centers and voxel num.
        """
        assert coors.shape[1] == 4
        batch_size = coors[-1][0] + 1
        batch_centers = []
        batch_voxel_num = []
        voxel_centers = coors[:, [3, 2, 1]].float()
        voxel_size = voxel_centers.new_tensor(self.voxel_size)
        pc_range_min = voxel_centers.new_tensor(self.point_cloud_range[:3])

        voxel_centers = voxel_centers * voxel_size * scale_factor + pc_range_min

        voxel_centers.add_(0.5 * voxel_size * scale_factor)
        for i in range(batch_size):
            cur_voxel_centers = voxel_centers[coors[:, 0] == i]
            batch_centers.append(cur_voxel_centers)
            batch_voxel_num.append(cur_voxel_centers.shape[0])
        batch_centers = self.padded_batch_points(batch_centers)
        return batch_centers, batch_voxel_num

    def forward(self, batch_inputs_dict: dict, feats_dict: dict, rpn_results_list: List[InstanceData]) -> Dict[Tensor]:
        """Extract key points features from multi-source features.

        Args:
            batch_inputs_dict (dict): The model input dict which include
                'points', 'img' keys.

                    - points (list[torch.Tensor]): Point cloud of each sample.
                    - imgs (torch.Tensor, optional): Image of each sample.
            feats_dict (dict): Multi-source features.
            rpn_results_list (List[:obj:`InstancesData`], optional): Detection results
                of rpn head.

        Returns:
            Dict: Include key points and key points features.
        """
        batch_inputs_dict['voxel_dict'] = feats_dict.pop('voxel_dict')
        batch_keypoints = self.sample_key_points(batch_inputs_dict)[...,:3]
        batch_raw_points = self.padded_batch_points(batch_inputs_dict['points'])
        point_features_list = []
        num_keypoints = batch_keypoints.shape[1]

        if self.bev_cfg:
            spatial_feats = feats_dict['spatial_feats']
            keypoint_bev_features = self.interpolate_from_bev_features(
                batch_keypoints, spatial_feats, self.bev_cfg.scale_factor)
            point_features_list.append(keypoint_bev_features)

        if self.rawpoint_sa_cfg:
            _, pooled_features, _ = \
                self.aggregate_keypoint_features_from_one_source(self.rawpoints_sa_layer,
                                                                 points_xyz=batch_raw_points[:, :, :3].contiguous(),
                                                                 features=batch_raw_points[:, :, 3:].transpose(1, 2),
                                                                 target_xyz=batch_keypoints.contiguous())
            point_features_list.append(pooled_features)

        for i, voxel_sa_layer in enumerate(self.voxel_sa_layers):
            cur_coords = feats_dict['multi_scale_3d_feats'][i].indices
            cur_feats = feats_dict['multi_scale_3d_feats'][i].features.contiguous()
            batch_voxel_centers, batch_voxel_num = self.get_voxel_centers(
                coors=cur_coords,
                scale_factor=self.downsample_scale_factor[i])
            batch_cur_feats = self.padded_batch_points(torch.split(cur_feats,batch_voxel_num,dim=0))
            _, pooled_features, _ = self.aggregate_keypoint_features_from_one_source(
                self.voxel_sa_layers[i],
                points_xyz=batch_voxel_centers.contiguous(),
                features=batch_cur_feats.transpose(1, 2).contiguous(),
                target_xyz=batch_keypoints[:, :, :3].contiguous())
            point_features_list.append(pooled_features)
        batch_size = len(batch_inputs_dict['points'])
        keypoint_features = torch.cat(
            point_features_list, dim=-1).view(batch_size * num_keypoints, -1)
        fusion_point_features = self.point_feature_fusion(keypoint_features)

        return dict(
            keypoint_features=keypoint_features,
            fusion_keypoint_features=fusion_point_features,
            keypoints=batch_keypoints)
